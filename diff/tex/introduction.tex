\section{Introduction}\label{sec-introduction}

Recent years have witnessed the emergence of hardware trusted execution environments (TEEs) that enable efficient computation on untrusted platforms. 
%A prominent example is Intel SGX~\cite{mckeen2013innovative}, a TEE widely deployed on commercial-off-the-shelf (COTS) desktops and server processors, providing secure memory called \textit{enclave} to host confidential computing on sensitive data, which are protected from the adversary in control of the operating system and even with physical access to the data-processing machine. 
A prominent example such as Intel SGX~\cite{mckeen2013innovative} has already been supported by major cloud providers today, including Microsoft Azure and Google Cloud~\cite{russinovich2017introducing,asylo2019}, and its further adoption has been facilitated by the Confidential Computing Consortium~\cite{ccc2019}, a Linux Foundation project that brings together the biggest technical companies such as Intel, Google, Microsoft and IBM etc. However, before TEEs can see truly wide deployment for real-world confidential computing, key technical barriers still need to be overcome, \textit{remote attestation} in particular.

\vspace{3pt}\noindent\textbf{Remote attestation}. At the center of a TEE's trust model is remote attestation (RA), which allows the user of confidential computing to verify that the enclave code processing her sensitive data is correctly built and operates on a genuine TEE platform~\cite{zhang2017presence}, so her data is well protected. This is done on SGX through establishing a chain of trust rooted at a platform attestation key 
which is used to generate a \textit{Quote} -- a signed report that contains the measurement of the code and data in an enclave; the Quote is delivered to the data owner and checked against the signature and the expected measurement hash. This trust building process is contingent upon the availability of the measurement, which is calculated from the enclave program either by the data owner when the program is publicly available or by a trusted third party working on the owner's behalf. This becomes problematic when the program itself is private and cannot be exposed.
Programs may have exploitable bugs or they may write information out of the enclave through corrupted pointers easily.
\DIFaddbegin 

\DIFaddend For example, \DIFdelbegin \DIFdel{pharmaceutical companies want to search for suitable candidates for their drug trial without directly getting access to plaintext patient records or exposing their algorithm (carrying sensitive genetic markers discovered with million dollar investments) to the hospital}\DIFdelend \DIFaddbegin \DIFadd{a  pharmaceutical company can run its proprietary algorithm inside an enclave hosting patient medical records, without exposing the algorithm but can still ensure the hospital (the data owner) the compliance of its data use with the hospital's privacy policy. Another example can be a privacy-preserving credit evaluation service, in which a customer's transactions are only exposed to an enclave running the credit evaluation code in compliance with a set of public privacy-protection rules (such as GDPR).
We consider confidential computing as a service (}\textit{\DIFadd{CCaaS}}\DIFadd{) as a privacy extension of today's online data processing services like machine-learning as a service~\mbox{%DIFAUXCMD
\cite{russinovich2017introducing}}\hspace{0pt}%DIFAUXCMD
. CCaaS is hosted by the party that operates its own target binary on the data provided by its owner (e.g., an online image classifier to label uploaded user photos)}\DIFaddend . With applications of this kind on the rise, new techniques for protecting both data and code privacy are in great demand.  

\vspace{3pt}\noindent\textbf{Challenges}. To address this problem, we present in this paper a novel \textit{Delegated and flexible in-enclave code verification} (\textsc{Deflection}) model to enable verification of an enclave program's compliance with user-defined security policies without exposing its source or binary code to unauthorized parties involved. Under the \textsc{Deflection} model, a \textit{bootstrap enclave} whose code is public and verifiable through the Intel's remote attestation, is responsible for performing the compliance check on behalf of the participating parties, who even without access to the code or data to be attested, can be convinced that desired policies are faithfully enforced.  
However, building a system to support this model turns out to be nontrivial, due to the complexity in static analysis of enclave binary for policy compliance, the need to keep the verification mechanism, which is inside the enclave's \textit{trusted computing base} (\textit{TCB}), small, the demand for a quick turnaround from the enclave user, and the limited computing resources today's SGX provides (about 93 MB physical memory on most commercial hardware~\cite{chakrabarti2019scaling}). 
%Simply sand-boxing the enclave code to enforce security policies, however, does not work well. 
Although the shielding runtimes such as Library OSes~\cite{priebe2019sgx,shen2020occlum},  SCONE container~\cite{arnautov2016scone}, Ryoan sandbox~\cite{hunt2018ryoan} and the interpreters/compilers built for SGX~\cite{wang2019towards,wang2019running} enable confinement of unmodified binary in SGX  enclaves, they all rely on a heavy interface layer for in-enclave service code to interact with the OS/Hypervisor~\cite{lazard2018teeshift}, which introduces performance overhead. More importantly, the confinement mechanisms (sometimes including a whole interpreter) significantly increase the TCB, leading to \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{a }\DIFaddend challenge in ensuring its security~\cite{van2019tale}. In our research, we studied popular shielding runtimes, Graphene-SGX even includes more than 100 kLoCs, more than 50 MB in binary, based upon analysis of its code.

%\revise{\vspace{3pt}\noindent\textbf{Existing architectures of shielding runtimes}.  Library OSes~\cite{priebe2019sgx,shen2020occlum},  containers~\cite{arnautov2016scone}, and sandboxes~\cite{hunt2018ryoan} support  running  unmodified binary  in  SGX  enclaves. These solutions rely on a heavy interface layer for in-enclave service code interacting with the OS/Hypervisor, with a non-negligible performance overhead.Interpreters and compilers built for SGX~\cite{wang2019towards,wang2019running} also support in-enclave secure computing. However, they either introduce the language runtime environment or the whole code generator into the TCB, leading to a big uncertainty to security and performance~\cite{van2019tale}. }

%\weijie{Highlight the design principle of \textit{separating mechanism and policy}}

A promising direction we envision that could lead to a practical solution is \textit{\DIFdelbegin \DIFdel{proof-carry }\DIFdelend \DIFaddbegin \DIFadd{proof-carrying }\DIFaddend code} (\textit{PCC})~\cite{necula1997proof,schneider2001language}, a technique that enables a \textit{verification condition generator} (\textit{VCGen})~\cite{colby2000certifying,leroy2006formal,pirzadeh2010extended} to analyze a program and create a proof that attests the program's adherence to policies, and a \textit{proof checker} to verify the proof and the code. The hope is to keep the VCGen outside the enclave while keeping the proof checker inside the enclave small and efficient.  The problem is that this \textit{cannot} be achieved by existing approaches, which utilize formal verification (such as~\cite{necula2001oracle,pirzadeh2010extended}) to produce a proof that could be considerably larger than the original code. Actually, today's formal verification techniques, theorem proving in particular, are still less scalable, difficult to handle large code blocks when constructing a security proof~\cite{sinha2015moat}. 


\vspace{3pt}\noindent\textbf{Our solution}. In our research, we developed a new technique to instantiate the \textsc{Deflection} model on SGX. Our approach, has been inspired by PCC, but relies on program analysis and \DIFdelbegin %DIFDELCMD < \revise{SFI techniques}%%%
\DIFdelend \DIFaddbegin \DIFadd{Software-based Fault Isolation (SFI) techniques}\DIFaddend , particularly out-of-enclave targeted instrumentation for lightweight in-enclave information-flow confinement, instead of heavyweight theorem proving to ensure policy compliance of enclave code. More specifically, \textsc{Deflection} operates an untrusted \textit{code producer} as a compiler to build the binary code for a data-processing program (called \textit{target program}) and instrument it with a set of \textit{security annotations} for enforcing desired policies at runtime, together with a lightweight trusted \textit{code consumer} running in the bootstrap enclave to statically verify whether the target code indeed carries properly implanted security annotations.


To reduce the TCB and in-enclave computation, \textsc{Deflection} is designed to simplify the verification step by pushing out most computing burden to the code producer running outside the enclave. More specifically, the target binary is expected to be well formatted by the producer, with all its indirect control flows resolved, all possible jump target addresses specified on a list and enforced by security annotations.  In this way, the code consumer can check the target binary's policy compliance through lightweight \textit{Recursive Descent Disassembly} to inspect its complete control flow (Section~\ref{subsec-boundarychecking}), so as to ensure the presence of correctly constructed security annotations in front of each critical operation, such as load, store, enclave operations like OCall, and stack management (through a shadow stack). Any failure in such an inspection causes the rejection of the program. Also, since most code instrumentation (for injecting security annotations) is tasked to the producer, the code consumer does not need to make any change to the binary except relocating it inside the enclave. As a result, we only need a verifier with a vastly simplified disassembler, instead of a full-fledged, complicated binary analysis toolkit, to support categories of security policies, including data leak control, control-transfer management, self-modifying code block and side/covert channel mitigation in a small-size machine-language format (Section~\ref{subsec-policies}); in further work, other proofs could be extended given a formal model of the x64 instruction set (e.g., as in~\cite{morrisett1999system}).
A wider spectrum of policies can also be upheld by an extension of \textsc{Deflection}, as discussed in the paper (Section~\ref{sec-discussion}). 

%and multi-user isolation 

%To reduce the TCB and computations inside the bootstrap enclave, we move as much annotation generation workload as possible to the code producer and design simple-to-verify annotation formats. In this way, the code consumer only includes a simple disassembler, instead of a full-fledged, complicated binary analysis component, to verify the security checks. The verifier performs only a few simple binary rewriting by overwriting immediate operands in instructions and the policy-compliance verification is performed by traversing the code in a recursive descent manner. \kai{Reaching here, readers may think the contribution is only to shrink the code, and move unnecessary code outside the verifier.} The verifier defers the challenging problem of resolving indirect control flow to the code producer, requiring the code producer to provide a list of indirect control flow targets and security annotation before each indirect control flow for verifying the actual target at run-time. 


We implemented \textsc{Deflection} in our research, building the code producer on top of the LLVM compiler infrastructure and the code consumer based upon the Capstone disassembly framework~\cite{capstone} and the core disassembling engine for x86 architecture. 
Using this unbalanced design, our in-enclave program has only 2000 lines of source code, which is significantly smaller than other \DIFdelbegin \DIFdel{shileding runtimes. 
Theorem }\DIFdelend \DIFaddbegin \DIFadd{shielding runtimes. 
To port theorem }\DIFaddend prover Z3 \DIFaddbegin \DIFadd{into SGX}\DIFaddend , with 26 MB used in Moat~\cite{sinha2015moat}, is \DIFdelbegin \DIFdel{hard to be ported into SGX }\DIFdelend \DIFaddbegin \DIFadd{not easy }\DIFaddend as well, not only because of its size but also its inability to be statically linked against an enclave.
We further evaluated our implementation on micro-benchmarks (nBench), as well as macro-benchmarks, including credit scoring, HTTPS server, and also basic biomedical analysis algorithms.
%(sequence alignment, sequence generation, etc.) under the scenario of Confidential Computing as a Service. 

%For example, Ryoan uses NaCl's core library, whose binary is around 20 MB \weijie{Ryoan's code is released} and the LibOSes used by Graphene-SGX and Occlum are even bigger.
%PANOPLY offers two orders of magnitude lower TCB(about 20 KLOC in total
%libz3.so is 26M

\textsc{Deflection} incurs on average (calculated by geometric mean) 20\% performance overhead
%and less than 30\% storage overhead 
enforcing all the proposed security policies, and leads to around 10\% performance overhead
%and less than 20\% storage overhead 
without side/covert channel mitigation.
We have released our code on Github~\cite{our-prototype}.

%We observed a memory overhead from 3.8\% and 134\% and a slowdown merely 1.003$\times$ to 1.548$\times$. 
%\wenhao{geometry mean of the overhead is better}  

%on simple application bench
%geometry mean of performance overhead of P1~P5: 1.098
%geometry mean of performance overhead of P1~P6: 1.193
%geometry mean of storage overhead of P1~P5: 1.181
%geometry mean of storage overhead of P1~P6: 1.295
%on nbench
%geometry mean of performance overhead of P1~P5: 1.111
%geometry mean of performance overhead of P1~P6: 1.176

%The size of the code consumer is only 7.7 MB in total\kai{users may not know how small is 7.7MB, you may compare with other disassembing engines}\weijie{comparing ours with the verification toolset used by MOAT (disassembling and instruction modeling using BAP + transformation and annotation generation using BoogiePL + theorem proving using Z3), comparing ours with Ryoan (sandbox using NaCl)}, way less than a compiler/interpreter or a sandbox. The evaluation on several benchmarks and genomic processing algorithms shows that the size of the additional security annotation is between 3.8\% and 134\%, while the running time overhead is between 0.3\% and 54.8\%.


%the untrusted code producer by retrofitting the LLVM compiler infrastructure with a IR-level pass and a customized back-end pass. The code consumer is implemented inside the bootstrap enclave by tailoring the Capstone disassembly framework~\cite{capstone} and retaining the core disassembling engine for x86 architecture. The size of the code consumer is only 7.7 MB in total\kai{users may not know how small is 7.7MB, you may compare with other disassembing engines}\weijie{comparing ours with the verification toolset used by MOAT (disassembling and instruction modeling using BAP + transformation and annotation generation using BoogiePL + theorem proving using Z3), comparing ours with Ryoan (sandbox using NaCl)}, way less than a compiler/interpreter or a sandbox. The evaluation on several benchmarks and genomic processing algorithms shows that the size of the additional security annotation is between 3.8\% and 134\%, while the running time overhead is between 0.3\% and 54.8\%.

\vspace{3pt}\noindent\textbf{Contributions}. The contributions are outlined as follows:

\vspace{3pt}\noindent$\bullet$\textit{ New model}. We propose \textsc{Deflection}, a \revise{portable framework} that extends today's TEE to maintain the data owner's trust in protection of her enclave data, without exposing the code of the data-processing program. This is achieved through enforcing a set of security policies through a publicly verifiable bootstrap enclave. This new attestation model enables a wide spectrum of applications with great real-world demand in the confidential computing era. 
%that can enforce the privacy and security policies of both the code and data provided by untrusted parties, while preserving the confidentiality of them. We find that a number of application scenarios can be benefited from the proposed model.

\vspace{3pt}\noindent$\bullet$\textit{ New techniques}. We present the design for instantiating \textsc{Deflection} on SGX, following the idea of PCC. Our approach utilizes out-of-enclave code analysis and instrumentation to minimize the workload for in-enclave policy compliance check, which just involves a quick run of a well-formatted target binary for inspecting correct instrumentation. This simple design offers a much smaller TCB compared with existing solutions.   

%which consists of an untrusted code producer (which runs outside of the enclave) and a trusted code consumer (which runs in the bootstrap enclave). We illustrate how to use CAT to implement memory leak prevention policies and common SGX side/covert channel prevention policies. Such a design reduces the size of and computation inside the trusted code consumer and is scalable to real world applciations. 

\vspace{3pt}\noindent$\bullet$\textit{ Implementation and evaluation}. We implemented our design of \textsc{Deflection} and extensively evaluated our prototype on micro- and macro- benchmarks, together with popular biomedical algorithms.  Our experiments show that \textsc{Deflection} effectively enforces various security policies at small cost, with \revise{multiple level protections}. 


%\footnote{The current project code is available on (github link).}
%\end{itemize}

%\vspace{3pt}\noindent\textbf{Roadmap}. The rest of this paper is organized as follows. Section~\ref{sec-background} provides background information on Intel SGX and PCC; Section~\ref{sec-CAT} elaborates the Confidential attestation \weijie{} model, our design goals and the threat model; Section~\ref{sec-design} and Section~\ref{sec-implementation} provide the detailed design and implementation of our system;
% \textit{CAT}, and our system implementation in deploying PCC for the SGX environment. Section~\ref{sec-evaluation} reports the evaluation of our implementation; 
%discusses impacts of attacks against our system and performance evaluation. Discussions are made in Section~\ref{sec-discussion}. Section~\ref{sec-relatedwork} compares our work with related prior research, and Section~\ref{sec-conclusion} concludes the paper.