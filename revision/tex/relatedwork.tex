\section{Related Work}\label{sec-relatedwork}

\vspace{3pt}\noindent\textbf{Secure computing using SGX}.
Many existing works propose using SGX to secure cloud computing systems, e.g., VC3~\cite{schuster2015vc3}, TVM~\cite{hynes2018efficient}, by using 
sand-boxing, containers~\cite{tian2019practical}, and others~\cite{shinde2017panoply,shanker2020evaluation}. 
In-enclave JVM interpreter is also a good choice~\cite{jiang2020uranus}. These systems protect the enclave on untrusted platform, as a result, they either do not protect the code privacy or they consider a one-party scenario, i.e., the code and data needed for the computation are from the same participant. 
%In contrast, we consider 3 real world scenarios (CCaaS, CDaaS and CDCM) protecting code and data from multiple distrustful parties. 

\vspace{3pt}\noindent\textbf{Data confinement with SFI}.
Most related to our work are data confinement technologies, which confines untrusted code with confidentiality and integrity guarantees. Ryoan~\cite{hunt2018ryoan} and its follow-up work~\cite{hunt2018chiron} provide an distributed sand-box by porting NaCl to the enclave environment, confining untrusted data-processing modules to prevent leakage of the user’s input data. However the overhead of Ryoan turns out huge (e.g., 100\% on genes data) and was evaluated on an software emulator for supporting SGXv2 instructions.
XFI~\cite{erlingsson2006xfi} is the most representative unconventional PCC work based on SFI, which places a verifier at OS level, instead of a TEE. \revise{Our compiler-based generator is more efficient in providing forward-edge CFI and our runtime enforcement is simpler than inline reference monitor or dynamic binary translation used by traditional SFI}~\cite{zhou2014armlock,tan2017principles}. The advantage of our design compared to other state-of-the-art shielding runtimes (e.g., Occlum) is three-fold. Firstly, DEFLECTION is more general. The memory access check of Occlum relies on hardware (Intel MPX) which is no longer supported, significantly hindering deployment. Secondly, DEFLECTION has a smaller size of TCB. Other than importing Zydis and PyVEX (in Python) to be the disassembler and verifier, we shrank and modified Capstone (in C) to implement our smaller disassembler and verifier. Thirdly, DEFLECTION can mitigate some side/covert channel leaks while others provide no such protection.

\vspace{3pt}\noindent\textbf{Code privacy}.
Code secrecy is an easy to be ignored but very important issue~\cite{kuccuk2019managing}. TEEshift~\cite{lazard2018teeshift}, 
DynSGX~\cite{silva2017dynsgx} and SGXElide~\cite{bauman2018sgxelide} both make possible that developers execute their code privately in public cloud environments, enabling developers to better manage the scarce memory resources. However, they only care about the developer's privacy but ignore the confidentiality of data belonging to users. %\revise{Since the code provider will not expose any details, inferring unknown models without prior knowledge is highly impossible~\cite{tramer2016stealing}.\wenhao{do we need this sentence?}}

\vspace{3pt}\noindent\textbf{Confidentiality verification of enclave programs}.
With formal verification tools, Moat~\cite{sinha2015moat} and its follow-up works~\cite{sinha2016design} verify if an enclave program has the risk of data leakage. The major focus of them is to verify the confidentiality of an SGX application outside the enclave formally and independently. Although it is possible that the verification could be performed within a ``bootstrap enclave'', the TCB would include the IR level language (BoogiePL) interpreter~\cite{barnett2005boogie} and a theorem prover~\cite{de2008z3}. Moreover, neither of them can discharge the large overhead introduced by instruction modeling and assertion proving when large-scale real-world programs are verified.
%There are works to ~\cite{sinha2015moat,subramanyan2017formal}.

%\vspace{3pt}\noindent\textbf{Proof carrying code}.
%Our approach borrows the idea from PCC, however there are significant differences between the traditional PCC scheme and ours. Instead of using formal proof tools to generate proof annotations and verify them by a theorem prover, which cannot support large programs and has a large TCB, we let the proof generator (the customized LLVM) to provide rich control/data flow information and then check them strictly inside the enclave, which removes the compiler from the TCB and further helps saving memory consumption and performance overhead.



%Side channels have been recognized as a major threat for SGX. Attacks include cache, tlb, branch prediction, page table. Side channel defenses for SGX remains an important research problem. To the best of our knowledge, ours is the first work showing how to support verification of security policies for side channel defenses.


%The overhead for each check is far less than the solving expressions~\cite{de2008z3}, and the proof verifier does not have to traverse every execution path. XFI~\cite{erlingsson2006xfi} is the most representative unconventional PCC work, which places a verifier at OS level for minimizing the TCB. 
%However, it's problematic that XFI only protects forward edge control-flow integrity. 
%However, if we apply XFI to verify an SGX program but build a verifier as a kernel module inside the OS, it makes the scheme meaningless since the OS is also not trustworthy. 
%Another similar work to reduce the TCB greatly is the Flicker~\cite{mccune2008flicker}, which is a TPM-based solution to execute security-sensitive code in isolation from an OS.
%Unlike traditional methods including a VCGen into its trusted part~\cite{necula1997proof}, in our design, we let the proof generator (the customized LLVM) to provide rich control/data flow information and then check them strictly inside the enclave, which removes the compiler from the TCB and further helps saving memory consumption and performance overhead.
 

%while its confinement overhead is sometimes high (100\% on Genes data) and the checkpoint restore overhead is significant (55\% on Genes data) with SGXv2 instruction emulation. 



\ignore{
Many existing works have proposed approaches to perform privacy-preserving computation tasks or constitute a computing environment. There are quite some solutions using cryptography, e.g., fully homomorphic encryption (FHE)~\cite{gentry2009fully} that allows a computing task to be executed directly on encrypted data
%, and secure multi-party computation~\cite{jha2008towards} that enable different parties to jointly perform a computing task without disclosing their individual inputs to the others. 
However, these techniques often could not scale to meet the requirements for running complicated tasks.

A more scalable alternative solution is TEE, especially Intel SGX, which can run as fast as CPU allows except some small overheads introduced by encryption, decryption, and authentication~\cite{gueron2016memory}, and therefore can potentially achieve a performance that comes close to native execution (within one order of magnitude slowdown~\cite{tramer2018slalom}). 
Researchers proposed VC3, the first system that allows users to run distributed MapReduce computations in the cloud while keeping their code and data always encrypted~\cite{schuster2015vc3}. From then on, there are works to verify if a program has the risk of data leakage~\cite{sinha2015moat,subramanyan2017formal}.
TVM is also a Privacy-preserving Machine Learning framework that can be used on SGX\cite{hynes2018efficient}. But in threat models of theirs, the remote user owns both data and code, which means the code may not be attestable for confidentiality.
%\weijie{To the best of our knowledge, CAT seems not the first approach that can protect both code and data privacy, while keeping the enclave is attestable. The first one should be the VC3~\cite{schuster2015vc3}, but VC3 only can protect map-reduce like services. In VC3, both E- and the user's data are always kept encrypted.}
Ryoan~\cite{hunt2018ryoan} and its follow-up work~\cite{hesamifard2018privacy} provide an SFI-based distributed sandbox, confining untrusted data-processing modules to prevent leakage of the user’s input data, while its confinement overhead is sometimes high (100\% on Genes data) and the checkpoint restore overhead is significant (55\% on Genes data) with SGXv2 instruction emulation. 
MPTEE~\cite{zhao2020mptee} also introduces a loader and a trampoline table to ensure the dynamic changing of page privileges. And it applies some boundary check mechanisms like Intel MPX~\cite{shen2018isolate} to enforce memory permission integrity. Similar work such as Occlum~\cite{shen2020occlum} can also guarantee a secure and efficient multitasking environment.
%Moreover, those approaches do not take side channel leakage into consideration, which would be a threat to confidentiality partially.
%Researchers use SGX and other hardware features (Intel MPX) to build a multi-domain software fault isolation (SFI) scheme\cite{shen2018isolate}, which can isolate data and code domains.

However, if we only depend on SGX's built-in integrity protection mechanism - the RA protocol - the in-enclave code would be still unreliable and there is no privacy since the code must be public for attestation.
%\weijie{talk about the code privacy}
Code secrecy is is an easy to be ignored but very important issue~\cite{mazmudar2019mitigator,kuccuk2019managing}.
DynSGX~\cite{silva2017dynsgx} and SGXElide~\cite{bauman2018sgxelide} both make possible that developers execute their code privately in public cloud environments, enabling developers to better manage the scarce memory resources. However, they only care about the developer's privacy but ignore the confidentiality of data belonging to remote users. 
 

%Many works have pursued to reducing the system TCB. Glamdring~\cite{lind2017glamdring} can automatically partition the application into untrusted and trusted parts for SGX, reducing the TCB. But still, it does not care about the Intellectual Property of the developer's code.

%\weijie{the following work also do not consider the code privacy}

Although we learn from the principle of PCC to implement our scheme, there are some significant differences between the traditional PCC scheme and ours. Traditional PCC usually uses the theory of formal proof to abstract a model, generate proof annotations and verify them by a theorem prover. Such formal verification still has two limitations: the degree of automation (complex implementation) and the degree of availability (inadequate expressiveness)~\cite{d2008survey}. Instead, our scheme does not use the formal method but leverages the control/data flow analysis. The overhead for each check is far less than the solving expressions~\cite{de2008z3}, and the proof verifier does not have to traverse every execution path. XFI~\cite{erlingsson2006xfi} is the most representative unconventional PCC work, which places a verifier at OS level for minimizing the TCB. 
%However, it's problematic that XFI only protects forward edge control-flow integrity. 
However, if we apply XFI to verify an SGX program but build a verifier as a kernel module inside the OS, it makes the scheme meaningless since the OS is also not trustworthy. 
Another similar work to reduce the TCB greatly is the Flicker~\cite{mccune2008flicker}, which is a TPM-based solution to execute security-sensitive code in isolation from an OS.
Unlike traditional methods including a VCGen into its trusted part~\cite{necula1997proof}, in our design, we let the proof generator (the customized LLVM) to provide rich control/data flow information and then check them strictly inside the enclave, which removes the compiler from the TCB and further helps saving memory consumption and performance overhead.

}